{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5dee72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365e044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('enrollment_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e82fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) #so that we can see all the columns or we can also transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b405a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_income</th>\n",
       "      <th>CAMPUS_VISIT</th>\n",
       "      <th>CAMPUS_VISIT_2</th>\n",
       "      <th>CONTACT_CODE1</th>\n",
       "      <th>Contact_Date</th>\n",
       "      <th>Contact_Month</th>\n",
       "      <th>Contact_Year</th>\n",
       "      <th>distance</th>\n",
       "      <th>Target_Enroll</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>hscrat</th>\n",
       "      <th>ID</th>\n",
       "      <th>init_span</th>\n",
       "      <th>Instate</th>\n",
       "      <th>int1rat</th>\n",
       "      <th>int2rat</th>\n",
       "      <th>interest</th>\n",
       "      <th>IRSCHOOL</th>\n",
       "      <th>LEVEL_YEAR</th>\n",
       "      <th>mailq</th>\n",
       "      <th>premiere</th>\n",
       "      <th>REFERRAL_CNTCTS</th>\n",
       "      <th>satscore</th>\n",
       "      <th>SELF_INIT_CNTCTS</th>\n",
       "      <th>sex</th>\n",
       "      <th>SOLICITED_CNTCTS</th>\n",
       "      <th>telecq</th>\n",
       "      <th>TERRITORY</th>\n",
       "      <th>TOTAL_CONTACTS</th>\n",
       "      <th>TRAVEL_INIT_CNTCTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EML</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.02038</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FR04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SAT</td>\n",
       "      <td>12</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.02038</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FR04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C01</td>\n",
       "      <td>16</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.02038</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FR04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EML</td>\n",
       "      <td>11</td>\n",
       "      <td>Mar</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>151</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.02038</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FR04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TFL</td>\n",
       "      <td>28</td>\n",
       "      <td>Mar</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>160</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.02038</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FR04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_income  CAMPUS_VISIT CAMPUS_VISIT_2 CONTACT_CODE1  Contact_Date  \\\n",
       "0         NaN             0              0           EML             1   \n",
       "1         NaN             0              0           SAT            12   \n",
       "2         NaN             0              0           C01            16   \n",
       "3         NaN             0              0           EML            11   \n",
       "4         NaN             0              0           TFL            28   \n",
       "\n",
       "  Contact_Month  Contact_Year  distance  Target_Enroll ETHNICITY    hscrat  \\\n",
       "0           Sep          2012       NaN              0       NaN  0.037652   \n",
       "1           Feb          2014       NaN              0         N  0.037652   \n",
       "2           Jan          2015       NaN              0         C  0.037652   \n",
       "3           Mar          2015       NaN              0       NaN  0.037652   \n",
       "4           Mar          2015       NaN              0         B  0.037652   \n",
       "\n",
       "    ID  init_span Instate   int1rat  int2rat  interest IRSCHOOL LEVEL_YEAR  \\\n",
       "0   32         48       N  0.017183  0.02038         0      NaN       FR04   \n",
       "1   51         31       N  0.017183  0.02038         0      NaN       FR04   \n",
       "2  120         20       N  0.017183  0.02038         0      NaN       FR04   \n",
       "3  151         18       N  0.017183  0.02038         0      NaN       FR04   \n",
       "4  160         18       N  0.017183  0.02038         0      NaN       FR04   \n",
       "\n",
       "   mailq  premiere  REFERRAL_CNTCTS  satscore  SELF_INIT_CNTCTS  sex  \\\n",
       "0      5         0                0       NaN                 1  1.0   \n",
       "1      5         0                0       NaN                 1  1.0   \n",
       "2      5         0                0       NaN                 0  1.0   \n",
       "3      5         0                0       NaN                 1  0.0   \n",
       "4      5         0                0    1090.0                 2  1.0   \n",
       "\n",
       "   SOLICITED_CNTCTS  telecq TERRITORY  TOTAL_CONTACTS  TRAVEL_INIT_CNTCTS  \n",
       "0                 0     NaN         N               1                   0  \n",
       "1                 0     NaN         N               1                   0  \n",
       "2                 1     NaN         N               1                   0  \n",
       "3                 0     NaN         N               1                   0  \n",
       "4                 0     NaN         N               2                   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c427195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_income</th>\n",
       "      <th>CAMPUS_VISIT</th>\n",
       "      <th>CAMPUS_VISIT_2</th>\n",
       "      <th>CONTACT_CODE1</th>\n",
       "      <th>Contact_Date</th>\n",
       "      <th>Contact_Month</th>\n",
       "      <th>Contact_Year</th>\n",
       "      <th>distance</th>\n",
       "      <th>Target_Enroll</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>hscrat</th>\n",
       "      <th>ID</th>\n",
       "      <th>init_span</th>\n",
       "      <th>Instate</th>\n",
       "      <th>int1rat</th>\n",
       "      <th>int2rat</th>\n",
       "      <th>interest</th>\n",
       "      <th>IRSCHOOL</th>\n",
       "      <th>LEVEL_YEAR</th>\n",
       "      <th>mailq</th>\n",
       "      <th>premiere</th>\n",
       "      <th>REFERRAL_CNTCTS</th>\n",
       "      <th>satscore</th>\n",
       "      <th>SELF_INIT_CNTCTS</th>\n",
       "      <th>sex</th>\n",
       "      <th>SOLICITED_CNTCTS</th>\n",
       "      <th>telecq</th>\n",
       "      <th>TERRITORY</th>\n",
       "      <th>TOTAL_CONTACTS</th>\n",
       "      <th>TRAVEL_INIT_CNTCTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>42857.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>19</td>\n",
       "      <td>Dec</td>\n",
       "      <td>2014</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>82215</td>\n",
       "      <td>21</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0</td>\n",
       "      <td>442241</td>\n",
       "      <td>FR04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>42857.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>15</td>\n",
       "      <td>Oct</td>\n",
       "      <td>2015</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82229</td>\n",
       "      <td>11</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>442242</td>\n",
       "      <td>FR04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>42857.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>21</td>\n",
       "      <td>Dec</td>\n",
       "      <td>2014</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>82239</td>\n",
       "      <td>21</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>442247</td>\n",
       "      <td>FR04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>28829.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LMI</td>\n",
       "      <td>18</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2015</td>\n",
       "      <td>532.482719</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>82321</td>\n",
       "      <td>19</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.052353</td>\n",
       "      <td>0.062907</td>\n",
       "      <td>0</td>\n",
       "      <td>442247</td>\n",
       "      <td>FR04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>15</td>\n",
       "      <td>Oct</td>\n",
       "      <td>2015</td>\n",
       "      <td>555.863190</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82327</td>\n",
       "      <td>11</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>442235</td>\n",
       "      <td>FR04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_income  CAMPUS_VISIT CAMPUS_VISIT_2 CONTACT_CODE1  Contact_Date  \\\n",
       "5155     42857.0             0              0           CIP            19   \n",
       "5156     42857.0             0              0           CIP            15   \n",
       "5157     42857.0             0              0           CIP            21   \n",
       "5158     28829.0             0              0           LMI            18   \n",
       "5159         NaN             0              0           CIP            15   \n",
       "\n",
       "     Contact_Month  Contact_Year    distance  Target_Enroll ETHNICITY  \\\n",
       "5155           Dec          2014  544.690969              0         H   \n",
       "5156           Oct          2015  544.690969              0       NaN   \n",
       "5157           Dec          2014  544.690969              0         N   \n",
       "5158           Feb          2015  532.482719              1         H   \n",
       "5159           Oct          2015  555.863190              0         H   \n",
       "\n",
       "        hscrat     ID  init_span Instate   int1rat   int2rat  interest  \\\n",
       "5155  0.018182  82215         21       Y  0.052247  0.074324         0   \n",
       "5156  0.000000  82229         11       Y  0.049270  0.056670         0   \n",
       "5157  0.016949  82239         21       Y  0.020906  0.056670         0   \n",
       "5158  0.016949  82321         19       Y  0.052353  0.062907         0   \n",
       "5159  0.000000  82327         11       Y  0.049270  0.056670         0   \n",
       "\n",
       "     IRSCHOOL LEVEL_YEAR  mailq  premiere  REFERRAL_CNTCTS  satscore  \\\n",
       "5155   442241       FR04      2         0                0       NaN   \n",
       "5156   442242       FR04      2         0                0       NaN   \n",
       "5157   442247       FR04      1         0                0       NaN   \n",
       "5158   442247       FR04      1         0                0    1200.0   \n",
       "5159   442235       FR04      5         0                0       NaN   \n",
       "\n",
       "      SELF_INIT_CNTCTS  sex  SOLICITED_CNTCTS  telecq TERRITORY  \\\n",
       "5155                 0  1.0                 0     4.0         5   \n",
       "5156                 1  1.0                 0     NaN         5   \n",
       "5157                 1  1.0                 0     4.0         5   \n",
       "5158                 7  0.0                 1     NaN         5   \n",
       "5159                 1  0.0                 0     NaN         8   \n",
       "\n",
       "      TOTAL_CONTACTS  TRAVEL_INIT_CNTCTS  \n",
       "5155               1                   1  \n",
       "5156               2                   1  \n",
       "5157               2                   1  \n",
       "5158               8                   0  \n",
       "5159               2                   1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11331d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avg_income',\n",
       " 'CAMPUS_VISIT',\n",
       " 'CAMPUS_VISIT_2',\n",
       " 'CONTACT_CODE1',\n",
       " 'Contact_Date',\n",
       " 'Contact_Month',\n",
       " 'Contact_Year',\n",
       " 'distance',\n",
       " 'Target_Enroll',\n",
       " 'ETHNICITY',\n",
       " 'hscrat',\n",
       " 'ID',\n",
       " 'init_span',\n",
       " 'Instate',\n",
       " 'int1rat',\n",
       " 'int2rat',\n",
       " 'interest',\n",
       " 'IRSCHOOL',\n",
       " 'LEVEL_YEAR',\n",
       " 'mailq',\n",
       " 'premiere',\n",
       " 'REFERRAL_CNTCTS',\n",
       " 'satscore',\n",
       " 'SELF_INIT_CNTCTS',\n",
       " 'sex',\n",
       " 'SOLICITED_CNTCTS',\n",
       " 'telecq',\n",
       " 'TERRITORY',\n",
       " 'TOTAL_CONTACTS',\n",
       " 'TRAVEL_INIT_CNTCTS']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2129cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5160 entries, 0 to 5159\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   avg_income          4397 non-null   float64\n",
      " 1   CAMPUS_VISIT        5160 non-null   int64  \n",
      " 2   CAMPUS_VISIT_2      5160 non-null   object \n",
      " 3   CONTACT_CODE1       5155 non-null   object \n",
      " 4   Contact_Date        5160 non-null   int64  \n",
      " 5   Contact_Month       5160 non-null   object \n",
      " 6   Contact_Year        5160 non-null   int64  \n",
      " 7   distance            4489 non-null   float64\n",
      " 8   Target_Enroll       5160 non-null   int64  \n",
      " 9   ETHNICITY           4562 non-null   object \n",
      " 10  hscrat              5160 non-null   float64\n",
      " 11  ID                  5160 non-null   int64  \n",
      " 12  init_span           5160 non-null   int64  \n",
      " 13  Instate             5160 non-null   object \n",
      " 14  int1rat             5160 non-null   float64\n",
      " 15  int2rat             5160 non-null   float64\n",
      " 16  interest            5160 non-null   int64  \n",
      " 17  IRSCHOOL            4735 non-null   object \n",
      " 18  LEVEL_YEAR          5160 non-null   object \n",
      " 19  mailq               5160 non-null   int64  \n",
      " 20  premiere            5160 non-null   int64  \n",
      " 21  REFERRAL_CNTCTS     5160 non-null   int64  \n",
      " 22  satscore            3273 non-null   float64\n",
      " 23  SELF_INIT_CNTCTS    5160 non-null   int64  \n",
      " 24  sex                 5033 non-null   float64\n",
      " 25  SOLICITED_CNTCTS    5160 non-null   int64  \n",
      " 26  telecq              2105 non-null   float64\n",
      " 27  TERRITORY           5160 non-null   object \n",
      " 28  TOTAL_CONTACTS      5160 non-null   int64  \n",
      " 29  TRAVEL_INIT_CNTCTS  5160 non-null   int64  \n",
      "dtypes: float64(8), int64(14), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b06d7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_income</th>\n",
       "      <th>CAMPUS_VISIT</th>\n",
       "      <th>Contact_Date</th>\n",
       "      <th>Contact_Year</th>\n",
       "      <th>distance</th>\n",
       "      <th>Target_Enroll</th>\n",
       "      <th>hscrat</th>\n",
       "      <th>ID</th>\n",
       "      <th>init_span</th>\n",
       "      <th>int1rat</th>\n",
       "      <th>int2rat</th>\n",
       "      <th>interest</th>\n",
       "      <th>mailq</th>\n",
       "      <th>premiere</th>\n",
       "      <th>REFERRAL_CNTCTS</th>\n",
       "      <th>satscore</th>\n",
       "      <th>SELF_INIT_CNTCTS</th>\n",
       "      <th>sex</th>\n",
       "      <th>SOLICITED_CNTCTS</th>\n",
       "      <th>telecq</th>\n",
       "      <th>TOTAL_CONTACTS</th>\n",
       "      <th>TRAVEL_INIT_CNTCTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4397.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>4489.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>3273.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>2105.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "      <td>5160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53494.747100</td>\n",
       "      <td>0.150194</td>\n",
       "      <td>15.707558</td>\n",
       "      <td>2014.610659</td>\n",
       "      <td>318.016140</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.088590</td>\n",
       "      <td>44615.840891</td>\n",
       "      <td>19.215891</td>\n",
       "      <td>0.045520</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.172093</td>\n",
       "      <td>3.893798</td>\n",
       "      <td>0.212984</td>\n",
       "      <td>0.064147</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>3.335659</td>\n",
       "      <td>0.617524</td>\n",
       "      <td>0.582946</td>\n",
       "      <td>2.141568</td>\n",
       "      <td>4.429651</td>\n",
       "      <td>0.446899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23083.609393</td>\n",
       "      <td>0.374771</td>\n",
       "      <td>8.799722</td>\n",
       "      <td>0.723275</td>\n",
       "      <td>370.781848</td>\n",
       "      <td>0.500048</td>\n",
       "      <td>0.145744</td>\n",
       "      <td>22348.233655</td>\n",
       "      <td>9.177806</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.039164</td>\n",
       "      <td>0.411876</td>\n",
       "      <td>1.600167</td>\n",
       "      <td>0.409456</td>\n",
       "      <td>0.288625</td>\n",
       "      <td>151.491442</td>\n",
       "      <td>3.098895</td>\n",
       "      <td>0.486040</td>\n",
       "      <td>0.761358</td>\n",
       "      <td>0.807467</td>\n",
       "      <td>3.480081</td>\n",
       "      <td>0.670228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9783.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>-216.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35568.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>102.461358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>28248.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48627.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>160.271705</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>45814.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68458.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>372.547430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>62830.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200001.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>3882.192379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>82327.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_income  CAMPUS_VISIT  Contact_Date  Contact_Year     distance  \\\n",
       "count    4397.000000   5160.000000   5160.000000   5160.000000  4489.000000   \n",
       "mean    53494.747100      0.150194     15.707558   2014.610659   318.016140   \n",
       "std     23083.609393      0.374771      8.799722      0.723275   370.781848   \n",
       "min      9783.000000      0.000000      1.000000   2010.000000     0.790555   \n",
       "25%     35568.000000      0.000000      7.000000   2014.000000   102.461358   \n",
       "50%     48627.000000      0.000000     16.000000   2015.000000   160.271705   \n",
       "75%     68458.000000      0.000000     23.000000   2015.000000   372.547430   \n",
       "max    200001.000000      2.000000     31.000000   2016.000000  3882.192379   \n",
       "\n",
       "       Target_Enroll       hscrat            ID    init_span      int1rat  \\\n",
       "count    5160.000000  5160.000000   5160.000000  5160.000000  5160.000000   \n",
       "mean        0.500000     0.088590  44615.840891    19.215891     0.045520   \n",
       "std         0.500048     0.145744  22348.233655     9.177806     0.035887   \n",
       "min         0.000000     0.000000     32.000000  -216.000000     0.000000   \n",
       "25%         0.000000     0.023529  28248.750000    12.000000     0.020906   \n",
       "50%         0.500000     0.052632  45814.000000    18.000000     0.049270   \n",
       "75%         1.000000     0.095238  62830.250000    23.000000     0.049270   \n",
       "max         1.000000     1.000000  82327.000000    72.000000     1.000000   \n",
       "\n",
       "           int2rat     interest        mailq     premiere  REFERRAL_CNTCTS  \\\n",
       "count  5160.000000  5160.000000  5160.000000  5160.000000      5160.000000   \n",
       "mean      0.051802     0.172093     3.893798     0.212984         0.064147   \n",
       "std       0.039164     0.411876     1.600167     0.409456         0.288625   \n",
       "min       0.000000     0.000000     1.000000     0.000000         0.000000   \n",
       "25%       0.020380     0.000000     2.000000     0.000000         0.000000   \n",
       "50%       0.056670     0.000000     5.000000     0.000000         0.000000   \n",
       "75%       0.056670     0.000000     5.000000     0.000000         0.000000   \n",
       "max       1.000000     3.000000     5.000000     1.000000         5.000000   \n",
       "\n",
       "          satscore  SELF_INIT_CNTCTS          sex  SOLICITED_CNTCTS  \\\n",
       "count  3273.000000       5160.000000  5033.000000       5160.000000   \n",
       "mean   1149.364497          3.335659     0.617524          0.582946   \n",
       "std     151.491442          3.098895     0.486040          0.761358   \n",
       "min     440.000000          0.000000     0.000000          0.000000   \n",
       "25%    1050.000000          1.000000     0.000000          0.000000   \n",
       "50%    1150.000000          3.000000     1.000000          0.000000   \n",
       "75%    1250.000000          5.000000     1.000000          1.000000   \n",
       "max    1600.000000         21.000000     1.000000          9.000000   \n",
       "\n",
       "            telecq  TOTAL_CONTACTS  TRAVEL_INIT_CNTCTS  \n",
       "count  2105.000000     5160.000000         5160.000000  \n",
       "mean      2.141568        4.429651            0.446899  \n",
       "std       0.807467        3.480081            0.670228  \n",
       "min       1.000000        1.000000            0.000000  \n",
       "25%       2.000000        1.000000            0.000000  \n",
       "50%       2.000000        3.000000            0.000000  \n",
       "75%       2.000000        7.000000            1.000000  \n",
       "max       4.000000       28.000000            5.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Statistical check\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8644ef4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4418\n",
       "1     709\n",
       "2      33\n",
       "Name: CAMPUS_VISIT, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CAMPUS_VISIT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd93208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4418\n",
       "1+     742\n",
       "Name: CAMPUS_VISIT_2, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CAMPUS_VISIT_2'].value_counts() #remove this column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edfacf",
   "metadata": {},
   "source": [
    "as both columns are same we can remove one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c277699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.856202\n",
       "1+    0.143798\n",
       "Name: CAMPUS_VISIT_2, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CAMPUS_VISIT_2'].value_counts(normalize = True)\n",
    "# using normalize = true gives the value counts in percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a917e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FR04    5160\n",
       "Name: LEVEL_YEAR, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LEVEL_YEAR'].value_counts() # remove this column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c475c6",
   "metadata": {},
   "source": [
    "we will remove this column as there is no variability\n",
    "so it will not have any influence on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c288a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1 2 3 4 5 6 7 #ID column #remove this column as the distribution is uniform\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1 2 3 4 5 6 7 #ID column #remove this column as the distribution is uniform\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e38e267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192     1\n",
       "75731    1\n",
       "52607    1\n",
       "72477    1\n",
       "52603    1\n",
       "        ..\n",
       "25293    1\n",
       "43724    1\n",
       "31434    1\n",
       "70343    1\n",
       "10239    1\n",
       "Name: ID, Length: 5160, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ID'].value_counts() # remove this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a09414f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    3701\n",
       "N    1459\n",
       "Name: Instate, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Instate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b3a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feb    785\n",
       "Oct    687\n",
       "Mar    602\n",
       "Nov    512\n",
       "Dec    491\n",
       "Jul    394\n",
       "Jan    392\n",
       "Apr    388\n",
       "Sep    359\n",
       "May    215\n",
       "Jun    192\n",
       "Aug    143\n",
       "Name: Contact_Month, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Contact_Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9513729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     376\n",
       "25    269\n",
       "23    260\n",
       "26    239\n",
       "18    230\n",
       "20    212\n",
       "6     211\n",
       "15    198\n",
       "21    188\n",
       "19    179\n",
       "27    178\n",
       "16    177\n",
       "17    174\n",
       "2     170\n",
       "7     169\n",
       "11    149\n",
       "14    143\n",
       "4     143\n",
       "5     141\n",
       "9     135\n",
       "28    135\n",
       "13    133\n",
       "29    131\n",
       "12    123\n",
       "8     116\n",
       "1     107\n",
       "10    103\n",
       "22    103\n",
       "30     97\n",
       "31     94\n",
       "24     77\n",
       "Name: Contact_Date, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Contact_Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8730c0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    661\n",
       "2    649\n",
       "3    644\n",
       "7    628\n",
       "6    608\n",
       "4    608\n",
       "1    597\n",
       "8    529\n",
       "A    134\n",
       "N    101\n",
       "0      1\n",
       "Name: TERRITORY, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TERRITORY'].value_counts() #remove this column as 'A', 'N', '0' is not integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c52a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447290    0.908131\n",
       "443509    0.696938\n",
       "445573    0.696938\n",
       "440324    0.696938\n",
       "441471    0.675818\n",
       "            ...   \n",
       "460085    0.021119\n",
       "444395    0.021119\n",
       "392998    0.021119\n",
       "431290    0.021119\n",
       "52020     0.021119\n",
       "Name: IRSCHOOL, Length: 1767, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IRSCHOOL'].value_counts(normalize=True)*100 #remove this column as they have too many unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c126f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['IRSCHOOL', 'TERRITORY', 'LEVEL_YEAR', 'CAMPUS_VISIT_2', 'ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dac853ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a424719f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_income</th>\n",
       "      <th>CAMPUS_VISIT</th>\n",
       "      <th>CONTACT_CODE1</th>\n",
       "      <th>Contact_Date</th>\n",
       "      <th>Contact_Month</th>\n",
       "      <th>Contact_Year</th>\n",
       "      <th>distance</th>\n",
       "      <th>Target_Enroll</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>hscrat</th>\n",
       "      <th>init_span</th>\n",
       "      <th>Instate</th>\n",
       "      <th>int1rat</th>\n",
       "      <th>int2rat</th>\n",
       "      <th>interest</th>\n",
       "      <th>mailq</th>\n",
       "      <th>premiere</th>\n",
       "      <th>REFERRAL_CNTCTS</th>\n",
       "      <th>satscore</th>\n",
       "      <th>SELF_INIT_CNTCTS</th>\n",
       "      <th>sex</th>\n",
       "      <th>SOLICITED_CNTCTS</th>\n",
       "      <th>telecq</th>\n",
       "      <th>TOTAL_CONTACTS</th>\n",
       "      <th>TRAVEL_INIT_CNTCTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>EML</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>48</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>SAT</td>\n",
       "      <td>12</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>31</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>C01</td>\n",
       "      <td>16</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>EML</td>\n",
       "      <td>11</td>\n",
       "      <td>Mar</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>TFL</td>\n",
       "      <td>28</td>\n",
       "      <td>Mar</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>42857.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>19</td>\n",
       "      <td>Dec</td>\n",
       "      <td>2014</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>21</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>42857.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>15</td>\n",
       "      <td>Oct</td>\n",
       "      <td>2015</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>42857.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>21</td>\n",
       "      <td>Dec</td>\n",
       "      <td>2014</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>21</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>28829.0</td>\n",
       "      <td>0</td>\n",
       "      <td>LMI</td>\n",
       "      <td>18</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2015</td>\n",
       "      <td>532.482719</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>19</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.052353</td>\n",
       "      <td>0.062907</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CIP</td>\n",
       "      <td>15</td>\n",
       "      <td>Oct</td>\n",
       "      <td>2015</td>\n",
       "      <td>555.863190</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5098 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_income  CAMPUS_VISIT CONTACT_CODE1  Contact_Date Contact_Month  \\\n",
       "0            NaN             0           EML             1           Sep   \n",
       "1            NaN             0           SAT            12           Feb   \n",
       "2            NaN             0           C01            16           Jan   \n",
       "3            NaN             0           EML            11           Mar   \n",
       "4            NaN             0           TFL            28           Mar   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "5155     42857.0             0           CIP            19           Dec   \n",
       "5156     42857.0             0           CIP            15           Oct   \n",
       "5157     42857.0             0           CIP            21           Dec   \n",
       "5158     28829.0             0           LMI            18           Feb   \n",
       "5159         NaN             0           CIP            15           Oct   \n",
       "\n",
       "      Contact_Year    distance  Target_Enroll ETHNICITY    hscrat  init_span  \\\n",
       "0             2012         NaN              0       NaN  0.037652         48   \n",
       "1             2014         NaN              0         N  0.037652         31   \n",
       "2             2015         NaN              0         C  0.037652         20   \n",
       "3             2015         NaN              0       NaN  0.037652         18   \n",
       "4             2015         NaN              0         B  0.037652         18   \n",
       "...            ...         ...            ...       ...       ...        ...   \n",
       "5155          2014  544.690969              0         H  0.018182         21   \n",
       "5156          2015  544.690969              0       NaN  0.000000         11   \n",
       "5157          2014  544.690969              0         N  0.016949         21   \n",
       "5158          2015  532.482719              1         H  0.016949         19   \n",
       "5159          2015  555.863190              0         H  0.000000         11   \n",
       "\n",
       "     Instate   int1rat   int2rat  interest  mailq  premiere  REFERRAL_CNTCTS  \\\n",
       "0          N  0.017183  0.020380         0      5         0                0   \n",
       "1          N  0.017183  0.020380         0      5         0                0   \n",
       "2          N  0.017183  0.020380         0      5         0                0   \n",
       "3          N  0.017183  0.020380         0      5         0                0   \n",
       "4          N  0.017183  0.020380         0      5         0                0   \n",
       "...      ...       ...       ...       ...    ...       ...              ...   \n",
       "5155       Y  0.052247  0.074324         0      2         0                0   \n",
       "5156       Y  0.049270  0.056670         0      2         0                0   \n",
       "5157       Y  0.020906  0.056670         0      1         0                0   \n",
       "5158       Y  0.052353  0.062907         0      1         0                0   \n",
       "5159       Y  0.049270  0.056670         0      5         0                0   \n",
       "\n",
       "      satscore  SELF_INIT_CNTCTS  sex  SOLICITED_CNTCTS  telecq  \\\n",
       "0          NaN                 1  1.0                 0     NaN   \n",
       "1          NaN                 1  1.0                 0     NaN   \n",
       "2          NaN                 0  1.0                 1     NaN   \n",
       "3          NaN                 1  0.0                 0     NaN   \n",
       "4       1090.0                 2  1.0                 0     NaN   \n",
       "...        ...               ...  ...               ...     ...   \n",
       "5155       NaN                 0  1.0                 0     4.0   \n",
       "5156       NaN                 1  1.0                 0     NaN   \n",
       "5157       NaN                 1  1.0                 0     4.0   \n",
       "5158    1200.0                 7  0.0                 1     NaN   \n",
       "5159       NaN                 1  0.0                 0     NaN   \n",
       "\n",
       "      TOTAL_CONTACTS  TRAVEL_INIT_CNTCTS  \n",
       "0                  1                   0  \n",
       "1                  1                   0  \n",
       "2                  1                   0  \n",
       "3                  1                   0  \n",
       "4                  2                   0  \n",
       "...              ...                 ...  \n",
       "5155               1                   1  \n",
       "5156               2                   1  \n",
       "5157               2                   1  \n",
       "5158               8                   0  \n",
       "5159               2                   1  \n",
       "\n",
       "[5098 rows x 25 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19336f7",
   "metadata": {},
   "source": [
    "5160-5098 = 62 duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75c7e3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_income             702\n",
       "CAMPUS_VISIT             0\n",
       "CONTACT_CODE1            5\n",
       "Contact_Date             0\n",
       "Contact_Month            0\n",
       "Contact_Year             0\n",
       "distance               610\n",
       "Target_Enroll            0\n",
       "ETHNICITY              586\n",
       "hscrat                   0\n",
       "init_span                0\n",
       "Instate                  0\n",
       "int1rat                  0\n",
       "int2rat                  0\n",
       "interest                 0\n",
       "mailq                    0\n",
       "premiere                 0\n",
       "REFERRAL_CNTCTS          0\n",
       "satscore              1825\n",
       "SELF_INIT_CNTCTS         0\n",
       "sex                    127\n",
       "SOLICITED_CNTCTS         0\n",
       "telecq                2994\n",
       "TOTAL_CONTACTS           0\n",
       "TRAVEL_INIT_CNTCTS       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c30d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df1.columns:\n",
    "    if df1[col].dtypes == int or df1[col].dtypes == float:\n",
    "        df2 = df1[col]\n",
    "        df2 = df2.dropna()\n",
    "        \n",
    "        if abs(np.mean(df2) - np.median(df2)) <= np.std(df2):\n",
    "            df1[col].fillna(np.mean(df2), inplace=True)\n",
    "        else:\n",
    "            df1[col].fillna(np.median(df2), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dba21c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_income              0\n",
       "CAMPUS_VISIT            0\n",
       "CONTACT_CODE1           5\n",
       "Contact_Date            0\n",
       "Contact_Month           0\n",
       "Contact_Year            0\n",
       "distance                0\n",
       "Target_Enroll           0\n",
       "ETHNICITY             586\n",
       "hscrat                  0\n",
       "init_span               0\n",
       "Instate                 0\n",
       "int1rat                 0\n",
       "int2rat                 0\n",
       "interest                0\n",
       "mailq                   0\n",
       "premiere                0\n",
       "REFERRAL_CNTCTS         0\n",
       "satscore                0\n",
       "SELF_INIT_CNTCTS        0\n",
       "sex                     0\n",
       "SOLICITED_CNTCTS        0\n",
       "telecq                  0\n",
       "TOTAL_CONTACTS          0\n",
       "TRAVEL_INIT_CNTCTS      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "401cad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped :  CONTACT_CODE1\n",
      "Dropped :  Contact_Month\n"
     ]
    }
   ],
   "source": [
    "for col in df1.columns:\n",
    "    if df1[col].dtypes == object or df1[col].dtypes == str:\n",
    "        df3 = df1[col]\n",
    "        df3 = df3.dropna()\n",
    "        unq_val = list(df3.unique())\n",
    "        \n",
    "        if len(unq_val) <= 10:\n",
    "            total_count = 0\n",
    "            val = str\n",
    "            for v in unq_val:\n",
    "                if v != 'nan':\n",
    "                    count = df3.loc[df3 == v]\n",
    "                    count = int(count.shape[0])\n",
    "                    \n",
    "                    if count >= total_count:\n",
    "                        total_count = count\n",
    "                        val = v\n",
    "            df1[col].fillna(val, inplace=True)\n",
    "            \n",
    "        else:\n",
    "            df1 = df1.drop(col, 1)\n",
    "            print('Dropped : ', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc443005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_income</th>\n",
       "      <th>CAMPUS_VISIT</th>\n",
       "      <th>Contact_Date</th>\n",
       "      <th>Contact_Year</th>\n",
       "      <th>distance</th>\n",
       "      <th>Target_Enroll</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>hscrat</th>\n",
       "      <th>init_span</th>\n",
       "      <th>Instate</th>\n",
       "      <th>int1rat</th>\n",
       "      <th>int2rat</th>\n",
       "      <th>interest</th>\n",
       "      <th>mailq</th>\n",
       "      <th>premiere</th>\n",
       "      <th>REFERRAL_CNTCTS</th>\n",
       "      <th>satscore</th>\n",
       "      <th>SELF_INIT_CNTCTS</th>\n",
       "      <th>sex</th>\n",
       "      <th>SOLICITED_CNTCTS</th>\n",
       "      <th>telecq</th>\n",
       "      <th>TOTAL_CONTACTS</th>\n",
       "      <th>TRAVEL_INIT_CNTCTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53496.498635</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>317.869926</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>48</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.14116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53496.498635</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>317.869926</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>31</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.14116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53496.498635</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2015</td>\n",
       "      <td>317.869926</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.14116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53496.498635</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>317.869926</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.14116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53496.498635</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2015</td>\n",
       "      <td>317.869926</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1090.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.14116</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>42857.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2014</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>21</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>42857.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2015</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.14116</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>42857.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2014</td>\n",
       "      <td>544.690969</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>21</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>28829.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "      <td>532.482719</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>19</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.052353</td>\n",
       "      <td>0.062907</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.14116</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>53496.498635</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2015</td>\n",
       "      <td>555.863190</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1149.364497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.14116</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5098 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        avg_income  CAMPUS_VISIT  Contact_Date  Contact_Year    distance  \\\n",
       "0     53496.498635             0             1          2012  317.869926   \n",
       "1     53496.498635             0            12          2014  317.869926   \n",
       "2     53496.498635             0            16          2015  317.869926   \n",
       "3     53496.498635             0            11          2015  317.869926   \n",
       "4     53496.498635             0            28          2015  317.869926   \n",
       "...            ...           ...           ...           ...         ...   \n",
       "5155  42857.000000             0            19          2014  544.690969   \n",
       "5156  42857.000000             0            15          2015  544.690969   \n",
       "5157  42857.000000             0            21          2014  544.690969   \n",
       "5158  28829.000000             0            18          2015  532.482719   \n",
       "5159  53496.498635             0            15          2015  555.863190   \n",
       "\n",
       "      Target_Enroll ETHNICITY    hscrat  init_span Instate   int1rat  \\\n",
       "0                 0         C  0.037652         48       N  0.017183   \n",
       "1                 0         N  0.037652         31       N  0.017183   \n",
       "2                 0         C  0.037652         20       N  0.017183   \n",
       "3                 0         C  0.037652         18       N  0.017183   \n",
       "4                 0         B  0.037652         18       N  0.017183   \n",
       "...             ...       ...       ...        ...     ...       ...   \n",
       "5155              0         H  0.018182         21       Y  0.052247   \n",
       "5156              0         C  0.000000         11       Y  0.049270   \n",
       "5157              0         N  0.016949         21       Y  0.020906   \n",
       "5158              1         H  0.016949         19       Y  0.052353   \n",
       "5159              0         H  0.000000         11       Y  0.049270   \n",
       "\n",
       "       int2rat  interest  mailq  premiere  REFERRAL_CNTCTS     satscore  \\\n",
       "0     0.020380         0      5         0                0  1149.364497   \n",
       "1     0.020380         0      5         0                0  1149.364497   \n",
       "2     0.020380         0      5         0                0  1149.364497   \n",
       "3     0.020380         0      5         0                0  1149.364497   \n",
       "4     0.020380         0      5         0                0  1090.000000   \n",
       "...        ...       ...    ...       ...              ...          ...   \n",
       "5155  0.074324         0      2         0                0  1149.364497   \n",
       "5156  0.056670         0      2         0                0  1149.364497   \n",
       "5157  0.056670         0      1         0                0  1149.364497   \n",
       "5158  0.062907         0      1         0                0  1200.000000   \n",
       "5159  0.056670         0      5         0                0  1149.364497   \n",
       "\n",
       "      SELF_INIT_CNTCTS  sex  SOLICITED_CNTCTS   telecq  TOTAL_CONTACTS  \\\n",
       "0                    1  1.0                 0  2.14116               1   \n",
       "1                    1  1.0                 0  2.14116               1   \n",
       "2                    0  1.0                 1  2.14116               1   \n",
       "3                    1  0.0                 0  2.14116               1   \n",
       "4                    2  1.0                 0  2.14116               2   \n",
       "...                ...  ...               ...      ...             ...   \n",
       "5155                 0  1.0                 0  4.00000               1   \n",
       "5156                 1  1.0                 0  2.14116               2   \n",
       "5157                 1  1.0                 0  4.00000               2   \n",
       "5158                 7  0.0                 1  2.14116               8   \n",
       "5159                 1  0.0                 0  2.14116               2   \n",
       "\n",
       "      TRAVEL_INIT_CNTCTS  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "5155                   1  \n",
       "5156                   1  \n",
       "5157                   1  \n",
       "5158                   0  \n",
       "5159                   1  \n",
       "\n",
       "[5098 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "realistic-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df1.columns:\n",
    "    if col != 'Target_Enroll' and df1[col].dtypes in ['int', 'float']:\n",
    "        mean = np.mean(df1[col])\n",
    "        max_val = np.max(df1[col])\n",
    "        min_val = np.min(df1[col])\n",
    "        df1[col] = pd.DataFrame(map(lambda x: abs(x-mean)/(max_val - min_val), df1[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "continent-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4 = df1\n",
    "# shape = df1.shape\n",
    "\n",
    "# for col in df4.columns:\n",
    "#     if df4[col].dtypes == object or df4[col].dtypes == str:\n",
    "#         list1 = list(df4[col].unique())\n",
    "#         for val in list1:\n",
    "#             df1[str(col)+str(val)] = None\n",
    "            \n",
    "#             for i in range(df1.shape[0]):\n",
    "#                 if df1[col][i] == val:\n",
    "#                     df1[str(col)+str(val)][i] = 1\n",
    "#                 else:\n",
    "#                     df1[str(col)+str(val)][i] = 0\n",
    "#         df1 = df1.drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "respective-syndicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5098 entries, 0 to 5159\n",
      "Data columns (total 23 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   avg_income          5036 non-null   float64\n",
      " 1   CAMPUS_VISIT        5098 non-null   int64  \n",
      " 2   Contact_Date        5098 non-null   int64  \n",
      " 3   Contact_Year        5098 non-null   int64  \n",
      " 4   distance            5036 non-null   float64\n",
      " 5   Target_Enroll       5098 non-null   int64  \n",
      " 6   ETHNICITY           5098 non-null   object \n",
      " 7   hscrat              5036 non-null   float64\n",
      " 8   init_span           5098 non-null   int64  \n",
      " 9   Instate             5098 non-null   object \n",
      " 10  int1rat             5036 non-null   float64\n",
      " 11  int2rat             5036 non-null   float64\n",
      " 12  interest            5098 non-null   int64  \n",
      " 13  mailq               5098 non-null   int64  \n",
      " 14  premiere            5098 non-null   int64  \n",
      " 15  REFERRAL_CNTCTS     5098 non-null   int64  \n",
      " 16  satscore            5036 non-null   float64\n",
      " 17  SELF_INIT_CNTCTS    5098 non-null   int64  \n",
      " 18  sex                 5036 non-null   float64\n",
      " 19  SOLICITED_CNTCTS    5098 non-null   int64  \n",
      " 20  telecq              5036 non-null   float64\n",
      " 21  TOTAL_CONTACTS      5098 non-null   int64  \n",
      " 22  TRAVEL_INIT_CNTCTS  5098 non-null   int64  \n",
      "dtypes: float64(8), int64(13), object(2)\n",
      "memory usage: 955.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ongoing-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dried-packet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5036, 23)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acknowledged-maintenance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    3189\n",
       "H     526\n",
       "N     437\n",
       "B     430\n",
       "A     289\n",
       "O     134\n",
       "I      31\n",
       "Name: ETHNICITY, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['ETHNICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "timely-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.get_dummies(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "welcome-workstation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_income</th>\n",
       "      <th>CAMPUS_VISIT</th>\n",
       "      <th>Contact_Date</th>\n",
       "      <th>Contact_Year</th>\n",
       "      <th>distance</th>\n",
       "      <th>Target_Enroll</th>\n",
       "      <th>hscrat</th>\n",
       "      <th>init_span</th>\n",
       "      <th>int1rat</th>\n",
       "      <th>int2rat</th>\n",
       "      <th>interest</th>\n",
       "      <th>mailq</th>\n",
       "      <th>premiere</th>\n",
       "      <th>REFERRAL_CNTCTS</th>\n",
       "      <th>satscore</th>\n",
       "      <th>SELF_INIT_CNTCTS</th>\n",
       "      <th>sex</th>\n",
       "      <th>SOLICITED_CNTCTS</th>\n",
       "      <th>telecq</th>\n",
       "      <th>TOTAL_CONTACTS</th>\n",
       "      <th>TRAVEL_INIT_CNTCTS</th>\n",
       "      <th>ETHNICITY_A</th>\n",
       "      <th>ETHNICITY_B</th>\n",
       "      <th>ETHNICITY_C</th>\n",
       "      <th>ETHNICITY_H</th>\n",
       "      <th>ETHNICITY_I</th>\n",
       "      <th>ETHNICITY_N</th>\n",
       "      <th>ETHNICITY_O</th>\n",
       "      <th>Instate_N</th>\n",
       "      <th>Instate_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>48</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>31</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>20</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>18</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.616777</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>18</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051176</td>\n",
       "      <td>2</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>0.055933</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.058438</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071310</td>\n",
       "      <td>31</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.022290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619613</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>0.055933</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.058438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.089492</td>\n",
       "      <td>21</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>0.055933</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.058438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072543</td>\n",
       "      <td>21</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.383223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619613</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>0.129680</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.055293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072543</td>\n",
       "      <td>11</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043651</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616777</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.061316</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089492</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.616777</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5036 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_income  CAMPUS_VISIT  Contact_Date  Contact_Year  distance  \\\n",
       "0       0.000000             0             1          2012  0.000000   \n",
       "1       0.000000             0            12          2014  0.000000   \n",
       "2       0.000000             0            16          2015  0.000000   \n",
       "3       0.000000             0            11          2015  0.000000   \n",
       "4       0.000000             0            28          2015  0.000000   \n",
       "...          ...           ...           ...           ...       ...   \n",
       "5093    0.055933             0            21          2014  0.058438   \n",
       "5094    0.055933             0            20          2014  0.058438   \n",
       "5095    0.055933             0            20          2014  0.058438   \n",
       "5096    0.129680             0            20          2015  0.055293   \n",
       "5097    0.000000             0             7          2015  0.061316   \n",
       "\n",
       "      Target_Enroll    hscrat  init_span   int1rat   int2rat  interest  mailq  \\\n",
       "0                 0  0.051840         48  0.028550  0.031654         0      5   \n",
       "1                 0  0.051840         31  0.028550  0.031654         0      5   \n",
       "2                 0  0.051840         20  0.028550  0.031654         0      5   \n",
       "3                 0  0.051840         18  0.028550  0.031654         0      5   \n",
       "4                 0  0.051840         18  0.028550  0.031654         0      5   \n",
       "...             ...       ...        ...       ...       ...       ...    ...   \n",
       "5093              1  0.071310         31  0.006514  0.022290         1      1   \n",
       "5094              0  0.089492         21  0.003537  0.004635         0      2   \n",
       "5095              0  0.072543         21  0.024827  0.004635         0      1   \n",
       "5096              0  0.072543         11  0.006620  0.010872         0      1   \n",
       "5097              1  0.089492         11  0.003537  0.004635         0      5   \n",
       "\n",
       "      premiere  REFERRAL_CNTCTS  satscore  SELF_INIT_CNTCTS       sex  \\\n",
       "0            0                0  0.000000                 1  0.383223   \n",
       "1            0                0  0.000000                 1  0.383223   \n",
       "2            0                0  0.000000                 0  0.383223   \n",
       "3            0                0  0.000000                 1  0.616777   \n",
       "4            0                0  0.051176                 2  0.383223   \n",
       "...        ...              ...       ...               ...       ...   \n",
       "5093         0                0  0.000000                 6  0.383223   \n",
       "5094         0                0  0.000000                 0  0.383223   \n",
       "5095         0                0  0.000000                 2  0.383223   \n",
       "5096         0                0  0.043651                 0  0.616777   \n",
       "5097         0                0  0.000000                 3  0.616777   \n",
       "\n",
       "      SOLICITED_CNTCTS    telecq  TOTAL_CONTACTS  TRAVEL_INIT_CNTCTS  \\\n",
       "0                    0  0.000000               1                   0   \n",
       "1                    0  0.000000               1                   0   \n",
       "2                    1  0.000000               1                   0   \n",
       "3                    0  0.000000               1                   0   \n",
       "4                    0  0.000000               2                   0   \n",
       "...                ...       ...             ...                 ...   \n",
       "5093                 1  0.619613              10                   3   \n",
       "5094                 0  0.000000               1                   1   \n",
       "5095                 0  0.619613               4                   2   \n",
       "5096                 0  0.000000               1                   1   \n",
       "5097                 1  0.000000               4                   0   \n",
       "\n",
       "      ETHNICITY_A  ETHNICITY_B  ETHNICITY_C  ETHNICITY_H  ETHNICITY_I  \\\n",
       "0               0            0            1            0            0   \n",
       "1               0            0            0            0            0   \n",
       "2               0            0            1            0            0   \n",
       "3               0            0            1            0            0   \n",
       "4               0            1            0            0            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5093            0            0            0            1            0   \n",
       "5094            0            0            0            1            0   \n",
       "5095            0            0            0            1            0   \n",
       "5096            0            0            0            1            0   \n",
       "5097            0            0            1            0            0   \n",
       "\n",
       "      ETHNICITY_N  ETHNICITY_O  Instate_N  Instate_Y  \n",
       "0               0            0          1          0  \n",
       "1               1            0          1          0  \n",
       "2               0            0          1          0  \n",
       "3               0            0          1          0  \n",
       "4               0            0          1          0  \n",
       "...           ...          ...        ...        ...  \n",
       "5093            0            0          0          1  \n",
       "5094            0            0          0          1  \n",
       "5095            0            0          0          1  \n",
       "5096            0            0          0          1  \n",
       "5097            0            0          0          1  \n",
       "\n",
       "[5036 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "republican-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(['ETHNICITY_O', 'Instate_Y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "received-horse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5036, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "disabled-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bizarre-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = new_df['Target_Enroll']\n",
    "X = new_df.drop('Target_Enroll', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aware-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5036, 27)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "marked-tribute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5036,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "broad-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "checked-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3525, 27)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "technical-address",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1511, 27)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eastern-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3525,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "secure-spoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1511,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "certain-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "occupied-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = [0.0001, 0.001, 0.1, 1, 10, 100]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "permanent-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "sporting-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_best_score = 0\n",
    "lgr_best_solver = str\n",
    "lgr_best_c = 0\n",
    "lgr_best_penalty = str\n",
    "kFolds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "comfortable-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\kiit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for s in range(len(solver)):\n",
    "    for c in range(len(C)):\n",
    "        for p in range(len(penalty)):\n",
    "            if solver[s] == 'newton-cg' or 'lbfgs':\n",
    "                if penalty[p] != 'l1':\n",
    "                    lgr = LogisticRegression(penalty = penalty[p], C = C[c], solver = solver[s], max_iter = 100)\n",
    "                    y_pred = cross_val_predict(lgr, x_train, y_train, cv = kFolds)\n",
    "                    F1_score = f1_score(y_train, y_pred)\n",
    "                    c_matrix = confusion_matrix(y_train, y_pred)\n",
    "                    hyper_params.append([solver[s], penalty[p], C[c]])\n",
    "                    f1_scores.append(F1_score)\n",
    "                    \n",
    "                    if F1_score >= lgr_best_score:\n",
    "                        lgr_best_score = F1_score\n",
    "                        lgr_best_solver = solver[s]\n",
    "                        lgr_best_c = C[c]\n",
    "                        lgr_best_penalty = penalty[p]\n",
    "            else:\n",
    "                lgr = LogisticRegression(penalty = penalty[p], C = C[c], solver = solver[s], max_iter = 100)\n",
    "                y_pred = cross_val_predict(lgr, x_train, y_train, cv = kFolds)\n",
    "                F1_score = f1_score(y_train, y_pred)\n",
    "                c_matrix = confusion_matrix(y_train, y_pred)\n",
    "                hyper_params.append([solver[s], penalty[p], C[c]])\n",
    "                f1_scores.append(F1_score)\n",
    "\n",
    "                if F1_score >= lgr_best_score:\n",
    "                    lgr_best_score = F1_score\n",
    "                    lgr_best_solver = solver[s]\n",
    "                    lgr_best_c = C[c]\n",
    "                    lgr_best_penalty = penalty[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "genuine-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['newton-cg', 'l2', 0.0001],\n",
       " ['newton-cg', 'l2', 0.001],\n",
       " ['newton-cg', 'l2', 0.1],\n",
       " ['newton-cg', 'l2', 1],\n",
       " ['newton-cg', 'l2', 10],\n",
       " ['newton-cg', 'l2', 100],\n",
       " ['lbfgs', 'l2', 0.0001],\n",
       " ['lbfgs', 'l2', 0.001],\n",
       " ['lbfgs', 'l2', 0.1],\n",
       " ['lbfgs', 'l2', 1],\n",
       " ['lbfgs', 'l2', 10],\n",
       " ['lbfgs', 'l2', 100],\n",
       " ['liblinear', 'l2', 0.0001],\n",
       " ['liblinear', 'l2', 0.001],\n",
       " ['liblinear', 'l2', 0.1],\n",
       " ['liblinear', 'l2', 1],\n",
       " ['liblinear', 'l2', 10],\n",
       " ['liblinear', 'l2', 100],\n",
       " ['sag', 'l2', 0.0001],\n",
       " ['sag', 'l2', 0.001],\n",
       " ['sag', 'l2', 0.1],\n",
       " ['sag', 'l2', 1],\n",
       " ['sag', 'l2', 10],\n",
       " ['sag', 'l2', 100],\n",
       " ['saga', 'l2', 0.0001],\n",
       " ['saga', 'l2', 0.001],\n",
       " ['saga', 'l2', 0.1],\n",
       " ['saga', 'l2', 1],\n",
       " ['saga', 'l2', 10],\n",
       " ['saga', 'l2', 100]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "thorough-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8727272727272728,\n",
       " 0.8825703724765425,\n",
       " 0.8893867264071689,\n",
       " 0.8873279010958134,\n",
       " 0.8877035373385739,\n",
       " 0.888015717092338,\n",
       " 0.8724754760530872,\n",
       " 0.8825703724765425,\n",
       " 0.8846806105144149,\n",
       " 0.8869467155342543,\n",
       " 0.8829847371396268,\n",
       " 0.8856338028169014,\n",
       " 0.8721500721500721,\n",
       " 0.8825703724765425,\n",
       " 0.888577041818692,\n",
       " 0.8855777340455441,\n",
       " 0.8877005347593583,\n",
       " 0.8878268203542311,\n",
       " 0.8716469570233631,\n",
       " 0.8728740270971461,\n",
       " 0.8732718894009216,\n",
       " 0.874496257915947,\n",
       " 0.8732718894009216,\n",
       " 0.8739205526770294,\n",
       " 0.8696402877697842,\n",
       " 0.8693394865878282,\n",
       " 0.8682842287694974,\n",
       " 0.8700662633246904,\n",
       " 0.8688382819256271,\n",
       " 0.8697406340057636]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eligible-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores.index(max(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "engaging-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['newton-cg', 'l2', 0.1]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "geological-complexity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8893867264071689"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "seeing-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "simplified-actress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l2'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_best_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "similar-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newton-cg'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_best_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sticky-swift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=5000, solver='newton-cg')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgr = LogisticRegression(penalty = lgr_best_penalty, C=lgr_best_c, solver = lgr_best_solver, max_iter=5000)\n",
    "best_lgr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "southern-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predictions = best_lgr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "operational-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(y_train, y_train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "serial-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892436974789916"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "sixth-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Y: Predictions')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiYklEQVR4nO3de5hddX3v8fdnLplkSLgmVE64BCaRkAI+khEUxaNQpzEpg5gEEmvPwYNcbFLa0vYoiS2UHnqxrdYLpxIRobQGEhQztiAjFbHaokwgXoINJ0F8SLQYEAEJ5Po9f6w1yd47+7ImZO29Mvm8nmc9s9bav732Z9aeme+s9Vv7txQRmJmZDWtrdQAzMysWFwYzMyvjwmBmZmVcGMzMrIwLg5mZlelodYCRmjhxYkyZMqXVMczMDiirV69+JiImZWl7wBWGKVOmMDQ01OoYZmYHFEk/zto2t1NJkm6R9DNJP6jxuCR9QtJ6Sd+TdEZeWczMLLs8jxhuBT4F/EONx98JTEuns4C/T7/mQn+qvDY9qgjR1d7FKztfAaCzrZPtu7bvfrxNbdx98d30n9wPwMC6AQY3DHLY2MP483/7893tXnPIa7jp/Ju44I4Lar4OQJB8wHL8mPFcddZVZduYN2MeK+evLHuN5195nr6ePr696dsMrBsoy9F/cj83nHvDXq81sG6Am4ZuAuCK3isAGNwwyNMvPc3Dmx6mo62Dk486mSt6r9i9vWrbuPq+q3n6paeZNXVWWa6+nr699ke1dTc+fOPu733Xtbtqvwk1VNu2HTya+f4rz08+S5oC/HNEnFrlsZuAr0fE8nR5HfC2iPhpvW329vbGSE8luSjsf6sWrAJg4RcWsmX7ltxe5+zjzmbNf60pe42Otg527NpRtf2Sc5aUFYeBdQPMXzmfbTu37X5um9p2L5fqau9ixfwVe/3SDawb4MI7L2RX7PljXpqru7Ob5XOXA3v2R7V1pUZaHAbWDey1bReHg8f+eP8lrY6I3ixtM59KktQ9ohSNTQaeKlnemK6r9tqXSxqSNLR58+b9HMP2xeCGQQY3DOZaFABW/2T1Xq9RqyhA8gtUanDDYFkR2LFrR9WiALB151YGNwzutX5ww2BZUajMtWX7lr32R7V1pYaPlLKqtm07eDT7/W9YGCSdLekx4D/T5ddJ+r+5pqoQEcsiojcieidNytSpbjnr6+mjr6eP7s79/f9CuZn/beZer9HRVvsMaOV/UX09fYxpH1P23NLlUl3tXfT19O21vq+njzaV/6qU5uru7N5rf1RbV2r4VFpW1bZtB49mv/8NTyVJ+jYwDxiIiNen635Q7fRQledOoQCnksCnk7JyH4P7GKyYXu37P5JTSZkKQ0ScJenRksLw3Yh4XYYgU6hdGOYAi4HZJJ3On4iIMxttc18Lg5nZwWwkhSHLVUlPSTobCEmdwO8CP8wQYjnwNmCipI3AtUAnQER8GriHpCisB7YA78sS2MzM8pWlMFwJfJykY3gTMAgsavSkiFjY4PHIsh0zM2uuhoUhIp4BfrMJWczMrAAaFgZJJwK/A0wpbR8R7v0yMxuFspxK+hLwWeDLwMgvpTAzswNKlsLwSkR8IvckZmZWCFkKw8clXUvS6bx1eGVEPJJbKjMza5ksheE04LeAc9lzKinSZTMzG2WyFIb5wEkRUX2AGTMzG1WyDKL3A+DwnHOYmVlBZDliOBz4T0kPU97H4MtVzcxGoSyF4drcU5iZWWFk+eTzg5J+BXhDuuo7EfGzfGOZmVmrZLkfw0XAd0g6oS8Cvi1pXt7BzMysNbKcSloKvGH4KEHSJOB+4K48g5mZWWtkuSqpreLU0bMZn2dmZgegLEcMX5F0H7A8Xb4YuDe/SGZm1kpZOp//SNK7gbekq5ZFxN35xjIzs1bJOuz2PRHxxXR5nKQpEfFk3uHMzKz5svQVrKR8uO2d6TozMxuFshSGjtJxktL5MflFMjOzVspSGDZL2j38haQLgGfyi2RmZq2U5aqkK4F/kvQpQMBTwP/INZWZmbVMlquSNgBvlDQ+Xf5l7qnMzKxlslyV1AXMBaYAHZIAiIjrc01mZmYtkeVU0irgeWA1JcNum5nZ6JSlMBwbEbNyT2JmZoWQ5aqkf5d0Wu5JzMysELIcMbwFuETSj0hOJQmIiDg912RmZtYSWQrDO3NPYWZmhVGzMEg6Mp19sUlZzMysAOodMawGguTUUaUATsolkZmZtVTNwhARJzYziJmZFYPvxGZmZmVcGMzMrIwLg5mZlclUGCS9RdL70vlJ6V3dzMxsFGpYGCRdC3wQuCZd1Qn8Y56hzMysdbIcMVwI9AMvAUTET4AJWTYuaZakdZLWS/pQlccvkbRZ0pp0ev9IwpuZ2f6X5ZPP2yIiJAWApEOybFhSO3Aj8A5gI/CwpIGIeKyi6Z0RsXgkoc3MLD9ZjhhWSLoJOFzSZcD9wGcyPO9MYH1EPJHeJ/oO4IJ9j2pmZs3QsDBExN8AdwFfAE4G/iQiPplh25NJbgM6bGO6rtJcSd+TdJek46ptSNLlkoYkDW3evDnDS5uZ2b7KciqJiPgq8NUcXv/LwPKI2CrpCuA24Nwqr78MWAbQ29sbOeQwM7NUlquSXpT0QsX0lKS7JdUbL2kTUHoEcGy6breIeDYihu8KdzMwc6TfgJmZ7V9Zjhj+juQ00OdJBtRbAPQAjwC3AG+r8byHgWnpZx42pc97T2kDScdExE/TxX7ghyOLb2Zm+1uWwtAfEa8rWV4maU1EfFDSklpPiogdkhYD9wHtwC0RsVbS9cBQRAwAV0nqB3YAPwcu2efvxMzM9osshWGLpItIOqAB5gGvpPN1z/dHxD3APRXr/qRk/hr2fHDOzMwKIMvlqr8J/BbwM+DpdP69ksYB/vyBmdko0/CIISKeAM6v8fA3928cMzNrtYaFQdJY4FLgV4Gxw+sj4n/lmMvMzFoky6mk24HXAL8OPEhy2anvA21mNkplKQxTI+KPgZci4jZgDnBWvrHMzKxVshSG7enXX0g6FTgMODq/SGZm1kpZLlddJukI4MPAADAe+ONcU5mZWcvULQyS2oAXIuI54BtAvSEwzMxsFKh7KikidgH/u0lZzMysALL0Mdwv6Q8lHSfpyOEp92RmZtYSWfoYLk6/LipZF/i0kpnZqJTlk88nNiOImZkVQ5b7MXRL+rCkZenyNEm/kX80MzNrhSx9DJ8DtgFnp8ubgP+TWyIzM2upLIWhJyI+QvpBt4jYQnLDHjMzG4WyFIZt6RDbASCpB9ha/ylmZnagynJV0nXAV4DjJP0T8GZ8pzUzs1Ery1VJg5JWA28kOYX0uxHxTO7JzMysJbLcj+HLwOeBgYh4Kf9IZmbWSln6GP4GOAd4TNJdkualN+8xM7NRKMuppAeBByW1A+cClwG3AIfmnM3MzFogS+cz6VVJ55MMj3EGcFueoczMrHWy9DGsAM4kuTLpU8CD6airZmY2CmU5YvgssDAidgJIeoukhRGxqMHzzMzsAJSlj+E+Sa+XtBC4CPgR8MXck5mZWUvULAySXgssTKdngDsBRcTbm5TNzMxaoN4Rw38C/wb8RkSsB5D0+01JZWZmLVPvcwzvBn4KPCDpM5LOw4PnmZmNejULQ0R8KSIWANOBB4DfA46W9PeS+pqUz8zMmqzhJ58j4qWI+HxEnA8cCzwKfDD3ZGZm1hJZhsTYLSKei4hlEXFeXoHMzKy1RlQYzMxs9HNhMDOzMi4MZmZWpmZhkHSPpCnp/LKKx5ZVfZKZmR3w6n3A7XPAoKTbgM9UPHZTfpHMzKyV6n2OYSXJENuHAjdL+kNJV0u6GvjvWTYuaZakdZLWS/pQlce7JN2ZPv7t4SMUMzNrnUaD6G0DXgK6gAlA5uG20xv73Ai8A9gIPCxpICIeK2l2KfBcREyVtAD4K5J7Pux3+lN/aDur6ROn8+LWF9n04iaOHHckP3/557sfa1c7Y9rHsGvXLrbu2kqHOjjh8BM4+aiTuXf9vQQBQFdbF+eddB5ffeKrbN+1nc62Tk7/ldN59KePsotdHNJ5CDtjJ6/seAWADnXwrlPexYNPPsgzW54hCCZPmMzGqzey9GtLGVg3QP/J/dxw7g11sw+sG2BwwyCHjT2M5195nr6ePvpP7q/abu6KuezYtYOxHWO59PWX1mw73P7q+67m6ZeeZtbUWaycv7JuhpuGkoPqK3qv2L3NcTeM45UdrzC2YywvL3257vdh1kqKiOoPSLOAjwIDwPURsWVEG5beBFwXEb+eLl8DEBF/UdLmvrTNf0jqAP4LmBS1QgG9vb0xNDQ0kiguCgew8WPG88ttv9y9vOScJTWLw8C6ARZ+YSFbtu/5Ue3u7Gb53OVlf/AH1g1wwR0X7PX8am2H219454XsKrkNybwZ86oWh4F1A8xfOZ9tO7cB0NXexYr5K7j4rot3F0HAxcGaTtLqiOjN0rbeVUlLgfkR8aGRFoXUZOCpkuWN6bqqbSJiB/A8cFTlhiRdLmlI0tDmzZv3IYodqEqLAiR/eGsZ3DBYVhQAtmzfwuCGwb3aVVOt7XD7XRX3pvraE1+rmWG4KABs3bmVwQ2DZUUB2GvZrEjq9TGcExFrmxmmlvTT1r0R0Ttp0qRWx7EmGj9mfNlyrVM9AH09fXR3dpet6+7spq+nb6921VRrO9y+TeW/KueedG7NDGPax+xe7mrvoq+nj7EdY8vaVS6bFUmen2PYBBxXsnxsuq5qm/RU0mHAs/s7SFxb88yUVTF94nQmT0gO7o4cd2TZY+1qZ1zHOLrauoCkb6DniB5mT52NSgbf7WrrYvbU2XS2dQLQ2dbJzGNm0pb+yB3SeUjZH8cOdTBvxjwmdU/avZ3JEybz4jUvsuScJZx69Kl1TyNBUjSWz13OojcsYsk5S1j0hkVVTw31n9zPqgWr6GhLutjGdoyt2Xa4/d0X303PET2MHzO+5mmk4bYr569k9tTZzJ46mxXzV9B/cj8vL3159/fr00hWdDX7GF71hpM/9I8D55EUgIeB95QehUhaBJwWEVemnc/vjoiL6m13X/oYzMwOdiPpY8itMKRBZgN/B7QDt0TEDZKuB4YiYkDSWOB24PXAz4EFEfFEg21uBn68j5EmktyNrqiKnK/I2aDY+YqcDYqdr8jZoNj5KrOdEBGZzsXnWhiKRtJQ1orZCkXOV+RsUOx8Rc4Gxc5X5GxQ7HyvJpvHSjIzszIuDGZmVuZgKwxFH/yvyPmKnA2Kna/I2aDY+YqcDYqdb5+zHVR9DGZm1tjBdsRgZmYNuDCYmVmZUVkYijzcd4Zsb5X0iKQdkuY1K9cI8l0t6TFJ35P0r5JOKFi+KyV9X9IaSd+UNKMo2UrazZUUkpp6mWOGfXeJpM3pvlsj6f1FyZa2uSj92Vsr6fPNypYln6SPley3xyX9okDZjpf0gKRH09/b2Q03GhGjaiL5MN0G4CRgDPBdYEZFm98GPp3OLwDuLFC2KcDpwD8A8wq4794OdKfzH2jWvhtBvkNL5vuBrxQlW9puAvAN4CGgt2D77hLgU838mRtBtmnAo8AR6fLRRcpX0f53SD7QW4hsJJ3QH0jnZwBPNtruaDxiOBNYHxFPRMQ24A6gcozlC4Db0vm7gPMkNWNs7obZIuLJiPgeI7j3RZPzPRB7Rtt9iGQMrCLle6Fk8RCgWVdXZPm5A/gzkvuONHt41az5WiFLtsuAGyPiOYCI+FnB8pVaCCxvSrJs2YLkhmuQjEf3k0YbHY2FYb8N992ibK000nyXAvfmmqhcpnySFknaAHwEuKoo2SSdARwXEf/SpEylsr63c9PTDXdJOq7K43nIku21wGslfUvSQ+n9Ypol8+9Femr1RKD6uOz7X5Zs1wHvlbQRuIfkiKau0VgYrAkkvRfoBf661VkqRcSNEdEDfBD4cKvzAEhqI7nx1R+0OksdXwamRMTpwFfZc1RdBB0kp5PeRvIf+WckHd7KQDUsAO6KiJ2tDlJiIXBrRBwLzAZuT38eaxqNhaEww33vY7ZWypRP0q+R3MipPyK2NikbjHz/3QG8K89AJRplmwCcCnxd0pPAG4GBJnZAN9x3EfFsyft5MzCzKNlI/hMeiIjtEfEjkpGbpxUo37AFNO80EmTLdimwAiAi/gMYSzLAXm3N6sBp1kTyn8UTJIdzw50xv1rRZhHlnc8ripKtpO2tNL/zOcu+ez1JZ9e0gr6300rmzycZybcQ2Sraf53mdj5n2XfHlMxfCDxUoGyzgNvS+Ykkp0+OKkq+tN104EnSDw4XJRvJ6d5L0vlTSPoY6mZsSvhmTySHS4+nf8CWpuuuJ/kPF5KKuRJYD3wHOKlA2d5A8t/RSyRHMWsLtu/uB54G1qTTQMHyfRxYm2Z7oN4f52Znq2jb1MKQcd/9Rbrvvpvuu+kFyiaSU3GPAd8nGaK/MPsuXb4O+Mtm5sq472YA30rf1zVAX6NtekgMMzMrMxr7GMzM7FVwYTAzszIuDGZmVqaj1QFGauLEiTFlypRWxzAzO6CsXr36mch4z+fcCoOkW4DfAH4WEadWeVwkV5DMBraQXE71SKPtTpkyhaGhof0d18xsVJP046xt8zyVdCvJtce1vJPkAyrTgMuBv88xC5KnLFNHB4wbt2d53Dhoa9uz3NkJAwN79uvAAMyZA7295ds55pjksVqv09aWvNbw8oQJsHRpeZtTTtnzGosXJ48vXpwsL10Kp52WfC2dr2Y445w5yfzw9k45Jfl+jjhiz2O1DAzA1KlJzvnzy3PVe15pu9LvbV9kfT0bnZr6/ud8fe0U4Ac1HrsJWFiyvI6SD9jUmmbOnBkjBZ7297RqVTKNGZPv60yeHNHdXb6uo6N2+yVLyt/7yowdHbUzd3Ul7SutWhXR1lbe9uyz9+Tq7q7+vOHnVuYfnkaidDv1Xs9Gp/3x/jOCD3u2svN5JANTXS5pSNLQ5s2bmxLO6hscTKZt2/J9nU2bYMuW8nU7dtRuX/nfVGXGHTtqZ966NWlfaXAQdlWMdbt69Z5cW7ZUf97wcyvz74vS7dR7PRudmv3+HxBXJUXEsojojYjeSZMy9Z1Yzvr6kmnMmHxfZ/Jk6O4uX9dRp2esv798uTJjR0ftzF1dSftKfX3Jqa9SM2fuydXdXf15w8+tzL8vSrdT7/VsdGr6+5/10GJfJgpyKik5jPKUZWpvjxg7ds/y2LER0p7ljo7yw9hVqyJmz46YObN8O695TfJYrdeRktcaXh4/PjkNVNpm+vQ9r7FoUfL4okXJ8pIlEaeemnwtna9mOOPs2XtOgS1alGy/oyPi8MP3PFbLqlURPT1JznnzynM1Oqwfbrevp5Eqt+PTSAenV/v+M4JTSbkOiZHeMvOfo/pVSXOAxSRXJZ0FfCIizmy0zd7e3vBVSWZmIyNpdURkGs03z8tVl5OMnT4xvUHEtUAnQER8muSGEbNJBrLbArwvryxmZpZdboUhIhY2eDxIhr82M7MCOSA6n83MrHlcGMzMrIwLg5mZlXFhMDOzMi4MZmZWxoXBzMzKuDCYmVkZFwYzMyvTsDBI6pHUlc6/TdJVkg7PPZmZmbVEliOGLwA7JU0FlgHHAZ/PNZWZmbVMlsKwKyJ2ABcCn4yIPwKOyTeWmZm1SpbCsF3SQuB/Av+cruvML5KZmbVSlsLwPuBNwA0R8SNJJwK35xvLzMxapeHoqhHxGHBVyfKPgL/KM5SZmbVOw8Ig6c3AdcAJaXuRjJp9Ur7RzMysFbLcj+GzwO8Dq4Gd+cYxM7NWy1IYno+Ie3NPYmZmhZClMDwg6a+BLwJbh1dGxCO5pTIzs5bJUhjOSr+W3kQ6gHP3fxwzM2u1LFclvb0ZQczMrBiyjJV0mKSPShpKp7+VdFgzwpmZWfNl+YDbLcCLwEXp9ALwuTxDmZlZ62TpY+iJiLkly38qaU1OeczMrMWyHDG8LOktwwvpB95ezi+SmZm1UpYjhg8At6X9CgJ+DlySZygzM2udLFclrQFeJ+nQdPmFvEOZmVnr1CwMkt4bEf8o6eqK9QBExEdzzmZmZi1Q74jhkPTrhCqPRQ5ZzMysAGoWhoi4KZ29PyK+VfpY2gFtZmajUJarkj6ZcZ2ZmY0C9foY3gScDUyq6Gc4FGjPO5iZmbVGvT6GMcD4tE1pP8MLwLw8Q5mZWevU62N4EHhQ0q0R8eMmZjIzsxbK0sdws6TDhxckHSHpvvwimZlZK2UpDBMj4hfDCxHxHHB0bonMzKylshSGXZKOH16QdAL+HIOZ2aiVpTAsBb4p6XZJ/wh8A7gmy8YlzZK0TtJ6SR+q8vglkjZLWpNO7x9ZfDMz29+yjJX0FUlnAG9MV/1eRDzT6HmS2oEbgXcAG4GHJQ1ExGMVTe+MiMUjzG1mZjmpecQgaXr69QzgeOAn6XR8uq6RM4H1EfFERGwD7gAuePWRzcwsT/WOGP4AuAz42yqPBXBug21PBp4qWd4InFWl3VxJbwUeB34/Ip6qbCDpcuBygOOPP77yYTMz24/qfY7hsvTr23N8/S8DyyNiq6QrgNuoUnAiYhmwDKC3t9cd32ZmOao3JMa76z0xIr7YYNubgONKlo9N15Vu49mSxZuBjzTYppmZ5azeqaTz069Hk4yZ9LV0+e3AvwONCsPDwDRJJ5IUhAXAe0obSDomIn6aLvYDP8we3czM8lDvVNL7ACQNAjOG/4BLOga4tdGGI2KHpMXAfSSD7t0SEWslXQ8MRcQAcJWkfmAHvmWomVkhKKL+KXtJP4yIU0qW24C1peuaqbe3N4aGhlrx0mZmByxJqyOiN0vbhp9jAP41HRtpebp8MXD/voYzM7Niy/IBt8WSLgTemq5aFhF35xvLzMxaJcsRA8AjwIsRcb+kbkkTIuLFPIOZmVlrNBwrSdJlwF3A8D2gJwNfyjGTmZm1UJZB9BYBbya5cxsR8f/wsNtmZqNWlsKwNR3rCABJHXjYbTOzUStLYXhQ0hJgnKR3ACtJhrIwM7NRKEth+CCwGfg+cAVwD/DhPEOZmVnr1L0qKb2nwtqImA58pjmRzMysleoeMUTETmBd6a09zcxsdMvyOYYjgLWSvgO8NLwyIvpzS2VmZi2TpTD8ce4pzMysMOrdj2EscCUwlaTj+bMRsaNZwczMrDXq9THcBvSSFIV3Uv0Wn2ZmNsrUO5U0IyJOA5D0WeA7zYlkZmatVO+IYfvwjE8hmZkdPOodMbxO0gvpvEg++fxCOh8RcWju6czMrOnq3dqzvZlBzMysGLIMiWFmZgcRFwYzMyvjwmBmZmVcGMzMrEzNwiDpHklT0vllFY8tq/okMzM74NW7XPVzwKCk29h7yO2bqrQ3M7NRoN7lqisl3UsyiN7Nkm4HdpU0WZ13ODMza75Go6tuIxlquwuYQHlhMDOzUaje6KqzgI8CA8AZEbGlaanMzKxl6h0xLAXmR8TaZoUxM7PWq9fHcE4zg5iZWTH4cwxmZlbGhcHMzMq4MJiZWRkXBjMzK+PCYGZmZVwYzMysjAuDmZmVybUwSJolaZ2k9ZI+VOXxLkl3po9/e3g0VzMza53cCoOkduBG4J3ADGChpBkVzS4FnouIqcDHgL/KL4+nrNMppyRTeztMmFD+WHs7dHfD2LHJcmcn9PbCwEB5u7FjYc4caGtLltvaknbt7cny+PHQ0bGnfWcnzJ8PRx+dzHd0wJvfnLx3S5fCaaclXxsZGIDFi5O2ixcny7XajR+fvPZRR9VvO9x+6tRkf8yfX7/dnDnJ9zpnTvk2h/flhAmNvw+zloqIXCbgTcB9JcvXANdUtLkPeFM63wE8A6jedmfOnBkjBZ4O1Gny5PLlJUtqv8+rVkV0d5e37+5O1le2k/Z+rWpth9u3tZW3nTeversxY8rbdXUl68ePL18/fvyIf4zNXhVgKCLb3+88TyVNBp4qWd6YrqvaJiJ2AM8DR1VuSNLlkoYkDW3evDmnuFZEmzaVL9f7r35wELZUDPW4ZUuyvrJdxN7Pr9Z2uP2uinGFv/a16u22bStft3Vrsv6XvyxfX7lsViQHROdzRCyLiN6I6J00aVKr41gTTa74V6K/v3bbvr7kNFep7u5kfWU7ae/nV2s73L6t4jfl3HOrtxszpnxdV1eyfvz48vWVy2ZFkmdh2AQcV7J8bLquahtJHcBhwLP7O0i1/w6ttunTk6mtbe8/YG1tMG5c8gcPkr6AmTNh1arydl1dMHv2nj/AUtJu+A/sIYck/Q3DOjpg3jyYNCmZb2+Hs8+GjRthyRI49dTk6w031M7d3w/Ll8OiRUnbRYuS5cpi0t8PX/pSkgHgyCNrtx1uf/fd0NOT7I9582DlyurtVq5Mvu+ZM5OvK1Yk6198cc++HD8+WTYrKkVOfzXTP/SPA+eRFICHgfdEyTDekhYBp0XElZIWAO+OiIvqbbe3tzeGhoZyyWxmNlpJWh0RvVnaNrqD2z6LiB2SFpN0MLcDt0TEWknXk3SCDACfBW6XtB74ObAgrzxmZpZNbkcMeZG0GfjxPj59IsmVT0VV5HxFzgbFzlfkbFDsfEXOBsXOV5nthIjI1El7wBWGV0PSUNZDqVYocr4iZ4Ni5ytyNih2viJng2LnezXZDoirkszMrHlcGMzMrMzBVhiWtTpAA0XOV+RsUOx8Rc4Gxc5X5GxQ7Hz7nO2g6mMwM7PGDrYjBjMza8CFwczMyozKwlDk+0BkyPZWSY9I2iFpXrNyjSDf1ZIek/Q9Sf8q6YSC5btS0vclrZH0zSpDvbcsW0m7uZJCUlMvc8yw7y6RtDndd2skvb8o2dI2F6U/e2slfb5Z2bLkk/Sxkv32uKRfFCjb8ZIekPRo+ns7u+FGsw7DeqBMJJ+y3gCcBIwBvgvMqGjz28Cn0/kFwJ0FyjYFOB34B2BeAffd24HudP4Dzdp3I8h3aMl8P/CVomRL200AvgE8BPQWbN9dAnyqmT9zI8g2DXgUOCJdPrpI+Sra/w7JSA+FyEbSCf2BdH4G8GSj7Y7GI4YzgfUR8UREbAPuAC6oaHMBcFs6fxdwnlRtvM3mZ4uIJyPie8CuahsoQL4HImJ4cOuHSAZHLFK+F0oWDwGadXVFlp87gD8juSHVK03KNSxrvlbIku0y4MaIeA4gIn5WsHylFgLLm5IsW7YADk3nDwN+0mijo7Ew7Lf7QLQoWyuNNN+lwL25JiqXKZ+kRZI2AB8BripKNklnAMdFxL80KVOprO/t3PR0w12SjqvyeB6yZHst8FpJ35L0kKRZTcoGI/i9SE+tnghUuWNHLrJkuw54r6SNwD0kRzR1jcbCYE0g6b1AL/DXrc5SKSJujIge4IPAh1udB0BSG/BR4A9anaWOLwNTIuJ04KvsOaougg6S00lvI/mP/DOSDm9loBoWAHdFxM5WBymxELg1Io4FZpMMXFr3b/9oLAyFuQ/EPmZrpUz5JP0asBToj4itTcoGI99/dwDvyjNQiUbZJgCnAl+X9CTwRmCgiR3QDfddRDxb8n7eDMwsSjaS/4QHImJ7RPyIZEj/aQXKN2wBzTuNBNmyXQqsAIiI/wDGkgywV1uzOnCaNZH8Z/EEyeHccGfMr1a0WUR55/OKomQraXsrze98zrLvXk/S2TWtoO/ttJL58xnBfW6b9d6m7b9Oczufs+y7Y0rmLwQeKlC2WcBt6fxEktMnRxUlX9puOvAkDe5b34J9dy9wSTp/CkkfQ92MTQnf7InkcOnx9A/Y0nTd9ST/4UJSMVcC64HvACcVKNsbSP47eonkKGZtwfbd/cDTwJp0GihYvo8Da9NsD9T749zsbBVtm1oYMu67v0j33XfTfTe9QNlEciruMeD7wIIi7bt0+TrgL5uZK+O+mwF8K31f1wB9jbbpITHMzKzMaOxjMDOzV8GFwczMyrgwmJlZGRcGMzMr48JgZmZlXBjMzKyMC4OZmZX5/z2+JgZg9j0xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.scatter(x_train['avg_income'], y_train, color = 'g', s=10)\n",
    "plt.ylabel('Y: Average Income')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.scatter(x_train['avg_income'], y_train_predictions, color = 'b', s=10)\n",
    "plt.ylabel('Y: Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-skiing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
